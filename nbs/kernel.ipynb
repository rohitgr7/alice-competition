{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "PATH = Path('./data')\n",
    "AUTHOR = 'Rohit_Gupta'\n",
    "SEED = 7\n",
    "TFIDF_PARAMS = {'max_features': 200000, 'ngram_range': (1, 7)}\n",
    "LOGIT_BEST_PARAMS = {'C': 7., 'solver': 'liblinear', 'random_state': SEED}\n",
    "\n",
    "# Site and time features in dataframe\n",
    "SITES = [f'site{i}' for i in range(1, 11)]\n",
    "TIMES = [f'time{i}' for i in range(1, 11)]\n",
    "\n",
    "def create_submission(test_preds, session_ids):\n",
    "    df = pd.DataFrame({'session_id': session_ids, 'target': test_preds})\n",
    "    df.to_csv(f'submission_alice_{AUTHOR}.csv', header=True, index=False)\n",
    "    return df\n",
    "\n",
    "def vectorize_sites(train_df, test_df, params):\n",
    "    train_sessions = train_df[SITES].fillna(0.).astype(np.int32).apply(lambda row: ' '.join(row.astype(np.str)), axis=1)\n",
    "    test_sessions = test_df[SITES].fillna(0.).astype(np.int32).apply(lambda row: ' '.join(row.astype(np.str)), axis=1)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(**params)\n",
    "    train_sessions = vectorizer.fit_transform(train_sessions)\n",
    "    test_sessions = vectorizer.transform(test_sessions)\n",
    "    \n",
    "    return vectorizer, train_sessions, test_sessions\n",
    "\n",
    "def add_time_features(df):\n",
    "    tmp_df = pd.DataFrame()\n",
    "    cat_feats = []\n",
    "    \n",
    "    # The original data was skewed so converted to log(1+x)\n",
    "    tmp_df['duration'] = np.log1p((df[TIMES].max(1) - df[TIMES].min(1)).dt.seconds)\n",
    "    \n",
    "    # Worked better than given in kernels\n",
    "    tmp_df['year_month'] = 12*(df['time1'].dt.year - 2013) + df['time1'].dt.month\n",
    "    cat_feats.append('year_month')\n",
    "    \n",
    "    # Month and Hour\n",
    "    tmp_df['start_month'] = df['time1'].dt.month\n",
    "    cat_feats.append('start_month')\n",
    "    tmp_df['start_hour'] = df['time1'].dt.hour\n",
    "    cat_feats.append('start_hour')\n",
    "    \n",
    "    # Weeks\n",
    "    tmp_df['week_of_year'] = df['time1'].dt.weekofyear\n",
    "    cat_feats.append('week_of_year')\n",
    "    tmp_df['start_weekday'] = df['time1'].dt.dayofweek\n",
    "    cat_feats.append('start_weekday')\n",
    "    \n",
    "    # Weekend?\n",
    "    tmp_df['weekend'] = (tmp_df['start_weekday'] > 4).astype(np.int32)\n",
    "    \n",
    "    # Daytime\n",
    "    tmp_df['day'] = ((df['time1'].dt.hour >= 6) & (df['time1'].dt.hour <= 11)).astype(np.int32)\n",
    "    tmp_df['evening'] = ((df['time1'].dt.hour >= 12) & (df['time1'].dt.hour <= 17)).astype(np.int32)\n",
    "    tmp_df['night'] = ((df['time1'].dt.hour >= 18) & (df['time1'].dt.hour <= 23)).astype(np.int32)\n",
    "\n",
    "    # Alice is mostly active in these hours\n",
    "    tmp_df['active1213'] = df['time1'].apply(lambda t: 12 <= t.hour <= 13).astype(np.int32)\n",
    "    tmp_df['active1618'] = df['time1'].apply(lambda t: 16 <= t.hour <= 18).astype(np.int32)\n",
    "    \n",
    "    return tmp_df, cat_feats\n",
    "\n",
    "def main():\n",
    "    # Get the data\n",
    "    print('[INFO] Loading data...')\n",
    "    train_df = pd.read_csv(PATH/'train_sessions.csv', parse_dates=TIMES)\n",
    "    test_df = pd.read_csv(PATH/'test_sessions.csv', parse_dates=TIMES)\n",
    "\n",
    "    train_df.drop('session_id', axis=1, inplace=True)    \n",
    "    train_df.drop_duplicates(inplace=True)\n",
    "    y_train = train_df.pop('target')\n",
    "    test_sessions = test_df.pop('session_id')\n",
    "    \n",
    "    # Tfidf vectorization\n",
    "    print('[INFO] Tfidf Vectorization...')\n",
    "    vectorizer, train_sites_vec, test_sites_vec = vectorize_sites(train_df, test_df, TFIDF_PARAMS)\n",
    "\n",
    "    # Time related features\n",
    "    print('[INFO] Adding time-related features...')\n",
    "    train_time_data, cat_feats = add_time_features(train_df)\n",
    "    test_time_data, _ = add_time_features(test_df)\n",
    "\n",
    "    # Categorical features to one-hot\n",
    "    print('[INFO] Converting to one-hot...')\n",
    "    train_split = train_df.shape[0]\n",
    "    full_time_data = pd.get_dummies(pd.concat((train_time_data, test_time_data)), columns=cat_feats)\n",
    "    train_oh_data = full_time_data[:train_split]\n",
    "    test_oh_data = full_time_data[train_split:]\n",
    "\n",
    "    # Stacking up and converting to sparse matrix\n",
    "    print('[INFO] Stacking up...')\n",
    "    train_data = hstack([train_sites_vec, train_oh_data]).tocsr()\n",
    "    test_data = hstack([test_sites_vec, test_oh_data]).tocsr()\n",
    "    \n",
    "    # Tuned hyerparameters by cross-validation\n",
    "    print('[INFO] Training...')\n",
    "    model = LogisticRegression(**LOGIT_BEST_PARAMS)\n",
    "    model.fit(train_data, y_train)\n",
    "    \n",
    "    print(sum(model.predict(test_data)))\n",
    "    print('[INFO] Predicting...')\n",
    "    test_preds = model.predict_proba(test_data)[:, 1]\n",
    "    \n",
    "    print('[INFO] Creating submission...')\n",
    "    test_sub = create_submission(test_preds, test_sessions)\n",
    "    print('[INFO] Done!!!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86b395bf891d6b86d66da31214b67df7232aa44e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
